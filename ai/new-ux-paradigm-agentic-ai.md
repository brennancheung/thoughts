# A New UX Paradigm for Agentic AI Workflows

Imagine a workspace where you orchestrate multiple AI agents like a conductor leading a symphony. Where each agent's output becomes another's input. Where complex multi-agent workflows are built from simple, composable operations.

This is an experimental interface for the agentic AI eraâ€”moving beyond chat to true agent orchestration.

## The Problem Nobody's Talking About

Current AI interfaces optimize for conversational familiarity at the cost of intellectual augmentation. They force linear, sequential conversations when human thought is inherently non-linear. We jump between ideas, explore tangents, filter possibilities, make unexpected connections. Chat interfaces trap this dynamic process in a rigid back-and-forth that fights against how we actually think.

Linear chat threads make it difficult to:
- Reference and reuse previous outputs in new contexts
- Orchestrate multiple AI agents working on different aspects of a problem
- See the full context of what each agent is processing
- Compose agentic operations into reusable patterns
- Branch into parallel explorations without losing context

These limitations force users into inefficient patterns and hide the true potential of AI agents as tools for augmenting human intellect.

## Thought Isn't Linear

Real intellectual work is messy. You start investigating one idea, which sparks three others. You pursue a tangent that becomes the main thread. You need to compare multiple possibilities simultaneously. You filter, recombine, and reorganize constantly.

This experimental interface embraces that reality. Instead of forcing your explorations into a linear chat, it provides a workspace where:
- Every AI interaction becomes a reusable artifact
- Multiple agents can work on parallel investigations  
- You can jump between different lines of inquiry without losing context
- Unexpected connections become visible and actionable
- The interface adapts to your thinking process, not the other way around

## Discovery Through Interaction

Most complex problems start with incomplete understanding. You have a vague sense of what you're investigating but not the precise questions to ask. Current interfaces force you to pretend otherwiseâ€”formulate a clear question, get an answer, repeat.

But effective problem-solving is iterative:
- Initial queries reveal better questions
- Each response opens new directions to explore
- Understanding builds through rapid experimentation
- The investigation evolves based on what you learn

This interface is designed for that reality. Start with partial ideas and refine them through interaction. Use early results to inform better queries. Let the AI help you discover what you're actually trying to understand.

Key principles:
- **Exploration is primary**: The interface assumes you're figuring things out as you go
- **Rapid iteration**: Quick cycles between query and response accelerate understanding  
- **Flexible pivoting**: Change direction based on what you discover
- **Visible history**: Past explorations remain available as you refine your approach
- **Collaborative discovery**: The AI helps identify promising directions, not just answer direct questions

## A Different Vision

This project applies three foundational principles from computer science pioneers to AI interaction:

**Douglas Engelbart's Augmentation Framework**: Make intellectual work visible and manipulable. Every AI interaction becomes an artifact you can inspect, reference, and reorganizeâ€”augmenting rather than automating human intellect.

**Kenneth Iverson's Notation Theory**: Notation is a tool of thought. We're developing a notation system for agentic AI workflowsâ€”making complex multi-agent operations expressible through concise, composable primitives.

**Bret Victor's Immediacy Principle**: Creators need immediate connection to their creation. AI responses stream in real-time, all context remains visible, and every operation provides instant feedback.

## What Makes This Different

### The Stack as Immediate Feedback

The stack interface embodies Victor's immediacy principle through fast interactive feedback loops:
- **See everything instantly**: Every operation immediately shows its result on the stack
- **No mental simulation**: The interface shows actual stateâ€”you don't "play computer" in your head
- **Live intermediate values**: Every step in the thinking process is visible and inspectable
- **Reduce cognitive strain**: Externalize mental models into visible, manipulable artifacts

This approach minimizes the discrepancy between your mental model and the actual AI interaction state.

## Core Features

### ðŸ¥ž **Stack-Based Workflow**
Every interaction pushes to a visible, manipulable stack. Your conversation becomes a collection of intellectual artifacts.


### ðŸ”„ **Composable Operations**
Reference any AI output by position (`{{#3}}`) or name (`{{@analysis}}`). Build complex workflows from simple parts.

### ðŸš€ **Immediate Feedback**
Streaming responses. Live updates. No waiting. Watch AI work in real-time.

### ðŸŽ¯ **Multiple Workspaces**
Run parallel explorations. Compare approaches. Maintain separate contexts. Orchestrate multiple agents when needed.

## A New Paradigm for AI Interaction

This experiment explores five key hypotheses:

1. **Artifacts > Conversations**: Treating AI interactions as manipulable artifacts enables more powerful workflows than chat metaphors
2. **Composable > Isolated**: Outputs that flow into new inputs create emergent capabilitiesâ€”especially for multi-agent workflows
3. **Visible > Hidden**: Making the complete interaction history and context visible improves understanding and control
4. **Notation as Tool of Thought**: Developing primitives for agentic workflows that shape how users compose AI operations
5. **Immediate > Asynchronous**: Real-time feedback maintains creative flow and enables rapid iteration

## Who Is This For?

This experiment appeals to those who:
- **Feel constrained by chat interfaces** when working with AI on complex problems
- **Think in systems and workflows** rather than isolated questions and answers
- **Want to see their thinking process** not just final results
- **Believe AI interaction can be more powerful** than current paradigms allow
- **Enjoy exploring new tools** that challenge conventional approaches

If you've ever lost track of context in a long AI conversation, wished you could reference earlier outputs without scrolling, or wanted to build complex workflows without copy-paste gymnasticsâ€”this exploration is for you.

This experiment is for those who understand that new paradigms require new ways of thinking. Just as mathematicians master notation to manipulate abstract concepts, or musicians internalize scales to improvise freely, mastering these new interaction patterns opens up possibilities for orchestrating AI capabilities that simpler interfaces can't provide. We're building for pioneers who know that the most powerful tools often require developing new mental modelsâ€”and who find that process exhilarating rather than daunting.

Remember the first time you saw a spreadsheet? Just a grid of empty boxesâ€”no instructions, no obvious purpose. Yet once you grasped that each cell could hold data or formulas that reference other cells, entire worlds opened up. Financial models, project plans, data analysisâ€”all from those "confusing" empty boxes. The most transformative tools often appear incomprehensible at first, until the moment they click.

## The Exploration Lab

This is an active research project investigating new interaction paradigms for AI systems. We test hypotheses through implementation and measure success through user workflows that weren't possible before.

Current research questions:
- What primitives make AI workflows natural to expressâ€”especially multi-agent orchestration?
- How can notation shape users' mental models of AI interaction and agent collaboration?
- What patterns emerge when AI interactions have immediate visibility?
- Can we develop a "vocabulary" of operations that scales from simple queries to complex agent compositions?
- How does making the augmentation process visible change problem-solving strategies?
- What new capabilities emerge from treating AI interactions as composable functions?

## Join the Exploration

- Read our [vision documents](https://github.com/brennancheung/forgepad/tree/main/docs/vision/index.md)
- Explore the codebase and experiment with new interaction patterns
- Share what you discover

## Building the Future

The future of AI interaction requires:
- Notation systems for expressing complex operationsâ€”from simple queries to multi-agent orchestration
- Explicit visibility into AI reasoning and workflows
- AI that augments human intelligence rather than replaces it
- Interfaces that match how we naturally think about complex problems

By making every AI interaction visible and manipulable, we eliminate the need to mentally track what you've asked, what the AI has seen, and how to connect outputs. For agentic workflows, this becomes even more criticalâ€”orchestrating multiple agents requires seeing the full picture.

This project serves as a testbed for these ideas. Our findings will contribute to the broader understanding of human-AI interaction design.

---

*This project is open source. We welcome contributions from developers, researchers, and practitioners interested in advancing AI interaction paradigms.*

*[GitHub](https://github.com/brennancheung/forgepad) | [Documentation](https://github.com/brennancheung/forgepad/tree/main/docs/vision/index.md) | [Community](#)*